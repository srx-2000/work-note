# 基础概念合集

## Zero-shot learing【零次学习】

### 第一版

这个第一版的理解是基于网络上搜到的一个例子：

>  假如模型已经通过学习知道了老虎，马，熊猫三个生物的图片特征，此时我们需要让这个学了上述特征的模型，分辨并告诉我们在一堆图片中哪个图片是斑马，在理想情况下模型会通过之前学到的老虎斑纹的特征，马形状的特征，以及熊猫颜色的特征成功的推理出斑马的特征应该是上述三种特征的综合，并最终给出一个正确的斑马的答案。

​	基于这个例子，其实不难发现Zero-shot learing本质上就是一个难度更高的推理任务【亦或是另一种意义上的迁移学习】，这种思想不仅可以用在图片的推理上，同样的也可以用在nlp以及一些多模态任务中，这种学习的好处是显而易见的，相较于常用的分类器等模型，该模型具有的智能更高，泛用性更高。

#### **较为笼统的定义**

​	模型通过对X1，Y1数据集的学习后【也就是说训练数据集是X1、Y1】，最终被应用在了一个X2，Y2数据集的任务中【也就是说测试数据集是X2、Y2】。其中两个数据集中的类别之间是没有交集的，但是同样的我们会给出对两个数据集中的类别的描述，使模型建立起两个数据集类别之间的联系。

![1685934618760](./基础概念合集.assets/1685934618760.jpg)

#### **可能存在的问题**

- **领域漂移问题（domain shift problem）**

​	该问题个人认为本质上还是一个泛化性的问题，

> 举一个例子，在模型训练好之后，得到了一个有尾巴的特征。但由于该模型在训练的时候是用的马的数据集进行训练的，所以在识别同样有尾巴的斑马和猪的情况下，对斑马的预测效果就会比较好，对猪的预测效果就会很差。

​	这主要是因为虽然模型都学习到了有尾巴这一特征，但在模型内部的视觉表达上显然猪尾巴的特征与马尾巴的视觉特征相距甚远，模型学习特征时是以像素为单位，所以更注重视觉特征，但二者的视觉特征相差过大，导致泛化性大大降低。

- **枢纽点问题（Hubness problem）**

​	对于该问题这里采用两种表述方式，

1. 比较抽象的：将高维向量投影到低维空间时，会出现中心性问题。这样的投影减少了方差，从而导致投影点聚集成中心点。
2. 符合我自己想象的解释有两种，至于到底是哪种可以由后续版本进行迭代：
   1. 第一种你可以想象高纬向量是一个浓缩的极小的球体，而低维向量则是一个展开了的大平面，我们通过一些投射函数将这个高纬向量投影成为这个大平面，那么此时的枢纽点问题就是由于高纬向量过于浓缩，导致在投影时可移动范围过小，从而导致投射出来的低维都是偏向于训练时语料占比较大那一部分的语义的。
   2. 第二种你可以反过来想，高纬向量就是一大片的平面，而低维向量则是一个较小的球体，我们同样是通过一些投射函数，将这个大平面映射成为这么一个小球。此时的枢纽点问题就变成了，由于投射函数将一个极大的物体投射到了一个小物体上，那么此时小物体中就很难再具有大物体时的一些距离特征，从而导致都聚集在了一个中心点，而在进行预测时往往是取中心点的预测结果，从而导致整体的预测结果变成了原语料中那部分占比更大，那么此时经过浓缩之后就更容易被找到。

​	对于上述我自己的两种想象表达上，我更偏向于第二种，因为在抽象表达中，提到了由于投影函数减少了方差，才导致了枢纽点问题的出现，这与将大物体投影到小物体上的想象更为接近一些【即：由于是一个浓缩的问题，所以大物体上原有的方差被缩小了】。

​	通过上述的表述不难发现，本质上有点类似于过拟合。由于使用了投影函数，导致在进行后续预测时，会出现对于语料占比的重度依赖。

- **语义间隔（semantic gap）**

​	这个问题比较难在细节上给出解释，可以大致理解为由于语言任务在一些方面的劣势，导致出现了类似于Gan网络中的问题【离散的语义无法很好的利用Gan网络的调整效果】，大致来说的话就是：样本的特征往往是视觉特征，比如用深度网络提取到的特征，而语义表示却是非视觉的，这直接反应到数据上其实就是：样本在特征空间中所构成的流型与语义空间中类别构成的流型是不一致的。（如下图所示）

![1685933272541](./基础概念合集.assets/1685933272541.jpg)

#### 应用

​	目前知道的GPT3应该是用到了zero-shot、one-shot、few-short learning，这也是在我读一个关于p-turning的知乎专栏时知道的，也正是因为这个所以才创了这个章节，专门说一些比较难懂的概念。

#### 参考文章

[知乎专栏](https://www.zhihu.com/tardis/bd/art/34656727?source_id=1001)，该文章还有很多可以深挖的地方，比如真正的代码实现，专栏里给出了部分代码和数学公式，但是由于第一版的认识并不足以支撑我去看懂，所以留着后续进一步展开。

## One-shot learning

### 第一版

这个本质上就是一个样本量极少的迁移学习。或者换一种表达方式，就是在上面zero-shot的基础上【zero-shot是一张相关的图片都没给，从模型中，通过给出的描述直接进行推测】，给了一张图片让他学。而few-shot则是在one-shot的基础上，将学习用的图片添加到了少量。如果添加到一定数量之后就可以认为是一个比较常用的迁移学习了。

## P-Turning

### 第一版

​	这里给出一个我在感性上的认识：这个P-Turning全称应该是：Prompt tuning。其本身是对大模型微调的一种技术，相较于传统微调【这里还不太清楚传统微调是怎么微调的，因为我对微调的第一个认知就是这种微调方式】，这种微调方式采用了冻结大模型的参数方式以便于减少大模型参数对内存和训练空间上的占用。

​	但是这种方式在普通大小的预训练模型下微调出来的效果并不是很好，同时在处理困难的语言序列标注任务时缺少普适性。所以清华的一批学者提出了P-Turning的第二版，具体可以看这个[论文](https://static.aminer.cn/upload/pdf/884/1862/1514/628749175aee126c0ffe1dc1_0.pdf)，对应本地的[p-turning v2.pdf](../article/p-turning v2.pdf)